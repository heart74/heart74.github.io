{"meta":{"title":"心脏i","subtitle":null,"description":null,"author":"heart74","url":"https://heart74.github.io"},"pages":[{"title":"bangumi","date":"2020-02-08T05:14:00.000Z","updated":"2020-02-12T06:03:21.000Z","comments":false,"path":"bangumi/index.html","permalink":"https://heart74.github.io/bangumi/index.html","excerpt":"","text":"","keywords":null},{"title":"about","date":"2020-02-08T05:14:00.000Z","updated":"2020-02-12T06:03:04.000Z","comments":false,"path":"about/index.html","permalink":"https://heart74.github.io/about/index.html","excerpt":"","text":"[heart心脏i] 与&nbsp; heart&nbsp; （ 真（ま）白（しろ） ） 对话中... bot_ui_ini()","keywords":"关于"},{"title":"comment","date":"2020-02-08T05:14:00.000Z","updated":"2020-02-12T06:03:30.000Z","comments":true,"path":"comment/index.html","permalink":"https://heart74.github.io/comment/index.html","excerpt":"","text":"念两句诗 叙别梦、扬州一觉。 【宋代】吴文英《夜游宫·人去西楼雁杳》","keywords":"留言板"},{"title":"client","date":"2020-02-08T05:14:00.000Z","updated":"2020-02-12T06:03:26.000Z","comments":false,"path":"client/index.html","permalink":"https://heart74.github.io/client/index.html","excerpt":"","text":"直接下载 or 扫码下载：","keywords":"Android客户端"},{"title":"donate","date":"2020-02-08T05:14:00.000Z","updated":"2020-02-12T06:03:37.000Z","comments":false,"path":"donate/index.html","permalink":"https://heart74.github.io/donate/index.html","excerpt":"","text":"","keywords":"喜欢的哥哥姐姐可以资助一下哟，万分感激~"},{"title":"lab","date":"2020-02-08T05:14:00.000Z","updated":"2020-02-12T06:11:21.000Z","comments":false,"path":"lab/index.html","permalink":"https://heart74.github.io/lab/index.html","excerpt":"","text":"sakura主题···更多好看的插件还在研究中。。。","keywords":"Lab实验室"},{"title":"links","date":"2020-02-08T05:14:00.000Z","updated":"2020-02-12T06:03:49.000Z","comments":true,"path":"links/index.html","permalink":"https://heart74.github.io/links/index.html","excerpt":"","text":"","keywords":"友人帐"},{"title":"music","date":"2020-02-08T05:14:00.000Z","updated":"2020-02-22T09:53:36.000Z","comments":false,"path":"music/index.html","permalink":"https://heart74.github.io/music/index.html","excerpt":"","text":"","keywords":"喜欢的音乐"},{"title":"rss","date":"2020-02-08T05:14:00.000Z","updated":"2020-02-12T06:03:59.000Z","comments":true,"path":"rss/index.html","permalink":"https://heart74.github.io/rss/index.html","excerpt":"","text":""},{"title":"tags","date":"2020-02-08T05:14:00.000Z","updated":"2020-02-12T06:04:04.000Z","comments":true,"path":"tags/index.html","permalink":"https://heart74.github.io/tags/index.html","excerpt":"","text":""},{"title":"theme-sakura","date":"2020-02-08T05:14:00.000Z","updated":"2020-02-12T06:09:56.000Z","comments":false,"path":"theme-sakura/index.html","permalink":"https://heart74.github.io/theme-sakura/index.html","excerpt":"","text":"Hexo主题Sakura由hojun大佬修改自WordPress主题Sakura，感谢原作者Mashiro和hojun","keywords":"Hexo 主题 Sakura 🌸"},{"title":"video","date":"2020-02-08T05:14:00.000Z","updated":"2020-02-12T06:04:27.000Z","comments":false,"path":"video/index.html","permalink":"https://heart74.github.io/video/index.html","excerpt":"","text":"var videos = [ { img: 'https://lain.bgm.tv/pic/cover/l/0e/1e/218971_2y351.jpg', title: '朝花夕誓——于离别之朝束起约定之花', status: '已追完', progress: 100, jp: 'さよならの朝に約束の花をかざろう', time: '放送时间: 2018-02-24 SUN.', desc: ' 住在远离尘嚣的土地，一边将每天的事情编织成名为希比欧的布，一边静静生活的伊欧夫人民。在15岁左右外表就停止成长，拥有数百年寿命的他们，被称为“离别的一族”，并被视为活着的传说。没有双亲的伊欧夫少女玛奇亚，过着被伙伴包围的平稳日子，却总感觉“孤身一人”。他们的这种日常，一瞬间就崩溃消失。追求伊欧夫的长寿之血，梅萨蒂军乘坐着名为雷纳特的古代兽发动了进攻。在绝望与混乱之中，伊欧夫的第一美女蕾莉亚被梅萨蒂带走，而玛奇亚暗恋的少年克里姆也失踪了。玛奇亚虽然总算逃脱了，却失去了伙伴和归去之地……。' }, { img : 'https://lain.bgm.tv/pic/cover/l/0e/1e/218971_2y351.jpg', title: '朝花夕誓——于离别之朝束起约定之花', status: '已追完', progress: 100, jp: 'さよならの朝に約束の花をかざろう', time: '2018-02-24 SUN.', desc: ' 住在远离尘嚣的土地，一边将每天的事情编织成名为希比欧的布，一边静静生活的伊欧夫人民。在15岁左右外表就停止成长，拥有数百年寿命的他们，被称为“离别的一族”，并被视为活着的传说。没有双亲的伊欧夫少女玛奇亚，过着被伙伴包围的平稳日子，却总感觉“孤身一人”。他们的这种日常，一瞬间就崩溃消失。追求伊欧夫的长寿之血，梅萨蒂军乘坐着名为雷纳特的古代兽发动了进攻。在绝望与混乱之中，伊欧夫的第一美女蕾莉亚被梅萨蒂带走，而玛奇亚暗恋的少年克里姆也失踪了。玛奇亚虽然总算逃脱了，却失去了伙伴和归去之地……。' } ] .should-ellipsis{overflow:hidden;text-overflow:ellipsis;white-space:nowrap;width:95%;}.should-ellipsis-full{overflow:hidden;text-overflow:ellipsis;white-space:nowrap;width:100%;}.should-ellipsis i{position:absolute;right:24px;}.grey-text{color:#9e9e9e !important}.grey-text.text-darken-4{color:#212121 !important}html{line-height:1.15;-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%}body{margin:0}img{border-style:none}progress{display:inline-block;vertical-align:baseline}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}html{-webkit-box-sizing:border-box;box-sizing:border-box}*,*:before,*:after{-webkit-box-sizing:inherit;box-sizing:inherit}ul:not(.browser-default){padding-left:0;list-style-type:none}ul:not(.browser-default)>li{list-style-type:none}.card{-webkit-box-shadow:0 2px 2px 0 rgba(0,0,0,0.14),0 3px 1px -2px rgba(0,0,0,0.12),0 1px 5px 0 rgba(0,0,0,0.2);box-shadow:0 2px 2px 0 rgba(0,0,0,0.14),0 3px 1px -2px rgba(0,0,0,0.12),0 1px 5px 0 rgba(0,0,0,0.2)}.hoverable{-webkit-transition:-webkit-box-shadow .25s;transition:-webkit-box-shadow .25s;transition:box-shadow .25s;transition:box-shadow .25s,-webkit-box-shadow .25s}.hoverable:hover{-webkit-box-shadow:0 8px 17px 0 rgba(0,0,0,0.2),0 6px 20px 0 rgba(0,0,0,0.19);box-shadow:0 8px 17px 0 rgba(0,0,0,0.2),0 6px 20px 0 rgba(0,0,0,0.19)}i{line-height:inherit}i.right{float:right;margin-left:15px}.bangumi .right{float:right !important}.material-icons{text-rendering:optimizeLegibility;-webkit-font-feature-settings:'liga';-moz-font-feature-settings:'liga';font-feature-settings:'liga'}.row{margin-left:auto;margin-right:auto;margin-bottom:20px}.row:after{content:\"\";display:table;clear:both}.row .col{float:left;-webkit-box-sizing:border-box;box-sizing:border-box;padding:0 .75rem;min-height:1px}.row .col.s12{width:100%;margin-left:auto;left:auto;right:auto}@media only screen and (min-width:601px){.row .col.m6{width:50%;margin-left:auto;left:auto;right:auto}}html{line-height:1.5;font-family:-apple-system,BlinkMacSystemFont,\"Segoe UI\",Roboto,Oxygen-Sans,Ubuntu,Cantarell,\"Helvetica Neue\",sans-serif;font-weight:normal;color:rgba(0,0,0,0.87)}@media only screen and (min-width:0){html{font-size:14px}}@media only screen and (min-width:992px){html{font-size:14.5px}}@media only screen and (min-width:1200px){html{font-size:15px}}.card{position:relative;margin:.5rem 0 1rem 0;background-color:#fff;-webkit-transition:-webkit-box-shadow .25s;transition:-webkit-box-shadow .25s;transition:box-shadow .25s;transition:box-shadow .25s,-webkit-box-shadow .25s;border-radius:2px}.card .card-title{font-size:24px;font-weight:300}.card .card-title.activator{cursor:pointer}.card .card-image{position:relative}.card .card-image img{display:block;border-radius:2px 2px 0 0;position:relative;left:0;right:0;top:0;bottom:0;width:100%}.card .card-content{padding:24px;border-radius:0 0 2px 2px}.card .card-content p{margin:0}.card .card-content .card-title{display:block;line-height:32px;margin-bottom:8px}.card .card-content .card-title i{line-height:32px}.card .card-reveal{padding:24px;position:absolute;background-color:#fff;width:100%;overflow-y:auto;left:0;top:100%;height:100%;z-index:3;display:none}.card .card-reveal .card-title{cursor:pointer;display:block}.waves-effect{position:relative;cursor:pointer;display:inline-block;overflow:hidden;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;-webkit-tap-highlight-color:transparent;vertical-align:middle;z-index:1;-webkit-transition:.3s ease-out;transition:.3s ease-out}.waves-effect img{position:relative;z-index:-1}.waves-block{display:block}::-webkit-input-placeholder{color:#d1d1d1}::-moz-placeholder{color:#d1d1d1}:-ms-input-placeholder{color:#d1d1d1}::-ms-input-placeholder{color:#d1d1d1}[type=\"radio\"]:not(:checked){position:absolute;opacity:0;pointer-events:none}[type=\"radio\"]:not(:checked)+span{position:relative;padding-left:35px;cursor:pointer;display:inline-block;height:25px;line-height:25px;font-size:1rem;-webkit-transition:.28s ease;transition:.28s ease;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}[type=\"radio\"]:not(:checked)+span:before,[type=\"radio\"]:not(:checked)+span:after{border-radius:50%}[type=\"radio\"]:not(:checked)+span:before,[type=\"radio\"]:not(:checked)+span:after{border:2px solid #5a5a5a}[type=\"radio\"]:not(:checked)+span:after{-webkit-transform:scale(0);transform:scale(0)}[type=\"checkbox\"]:not(:checked){position:absolute;opacity:0;pointer-events:none}[type=\"checkbox\"]:not(:checked):disabled+span:not(.lever):before{border:none;background-color:rgba(0,0,0,0.42)}[type=\"checkbox\"].filled-in:not(:checked)+span:not(.lever):before{width:0;height:0;border:3px solid transparent;left:6px;top:10px;-webkit-transform:rotateZ(37deg);transform:rotateZ(37deg);-webkit-transform-origin:100% 100%;transform-origin:100% 100%}[type=\"checkbox\"].filled-in:not(:checked)+span:not(.lever):after{height:20px;width:20px;background-color:transparent;border:2px solid #5a5a5a;top:0px;z-index:0}input[type=checkbox]:not(:disabled) ~ .lever:active:before,input[type=checkbox]:not(:disabled).tabbed:focus ~ .lever::before{-webkit-transform:scale(2.4);transform:scale(2.4);background-color:rgba(0,0,0,0.08)}input[type=range].focused:focus:not(.active)::-webkit-slider-thumb{-webkit-box-shadow:0 0 0 10px rgba(38,166,154,0.26);box-shadow:0 0 0 10px rgba(38,166,154,0.26)}input[type=range].focused:focus:not(.active)::-moz-range-thumb{box-shadow:0 0 0 10px rgba(38,166,154,0.26)}input[type=range].focused:focus:not(.active)::-ms-thumb{box-shadow:0 0 0 10px rgba(38,166,154,0.26)} 番组计划 这里将是永远的回忆 window.onload = function(){ videos.forEach(function(video, i){ $('#rootRow').append(` ${video.title} ${video.jp} ${video.status} ${video.title} ${video.jp} 放送时间: ${video.time} ${video.desc} ${video.status} `) }) }","keywords":"B站"}],"posts":[{"title":"transformer","slug":"transformer","date":"2023-09-22T11:45:13.000Z","updated":"2024-03-18T11:50:23.753Z","comments":true,"path":"2023/09/22/transformer/","link":"","permalink":"https://heart74.github.io/2023/09/22/transformer/","excerpt":"","text":"传统的序列转录模型，基于复杂的循环或者卷积，主流模型，trans都给换成多头注意力了 模型架构** 编码器6个layer，一个层有两个子层，一个是多头注意力层，一个是MLP，对每一个子层都用了残差连接，最后使用了layer normalization. output of 子层 LayerNorm(x + Sublayer(x))。残差需要输入和输出一样大小，简单起见每一个层的输出维度都是512。和CNN MLP不一样，要么维度下减，channel增加。 layer norm 和 batch norm 图中行代表样本，每一列一个特征，左图是BN，右图是LN（二维图像） 图中左边蓝色线是batch norm，取一个特征，把他样本里所有元素都搞出来，归一化。layer norm（黄线）针对一个样本，所有特征，做归一化 seq是序列长度，一个样本是一个序列，类比图像里的通道数，feature可以类比图像的（h*w = d） batch norm在一个batch里，在某个feature得维度（样本方向），把均值变成0，方差变成1；还会学习$\\lambda和\\beta$，任意方差为某个值，均值为某个值 layer norm在样本的维度，特征方向，做归一化 解码器和编码器不一样的是，用了第三个子层（掩码多头注意力层），解码器做的是自回归（当前输入是过去时刻的输出），但是在注意力机制里，每次能看到完整的输入，所以要把t时刻以后的mask起来。 Attention机制注意力函数是将一个query和一些key-value映射成一个输出的一个函数，都是向量，output是value的加权和。输出的维度和value的维度一致。每一个value的权重，是value对应的key和查询的query的相似度计算出来的 如图所示，value的靠左边的权重（粗线条），由于query和左边Key更相似，所以更大，output是V的加权和 Scaled Dot-Product Attention 两个向量做内积，值越大，越相似。所以这里V的权重是Q和K的内积，算出来后除以向量的维度，做scale，再用softmax得到权重。实际中用矩阵进行运算。 如上图，Q矩阵相乘后，对n*m矩阵除以√dk，然后对每一行做softmax，结果和V相乘得到输出矩阵（最右边）输出矩阵的每一行（和q一样有n行）就是一个查询对应的值 一般有两种比较常见注意力机制，一种叫加性的注意力，可以处理query和key不等长（维度？），一种叫做dot product注意力，和本文不一样的是本文除以了√dk。用dot product是因为更加简单高效。 当dk不是很大的时候除不除都没关系，当dk比较大的时候，做点积，值会比较大或者比较小，值比较大的时候，同一行相对值的方差就更大，经过softmax容易有单个值变成1，其他值更加向两端靠拢，导致梯度比较小，transfomer dk比较大，所以除一下比较好 mask机制 maks的效果是，让我t时刻的query只看t时刻前面对应的key-value pair，计算出QK矩阵之后，直接讲t时刻之后对应的值置为很大的负数，这样经过softmax就会变成0，从而实现忽略t时刻以后的k和v 多头注意力 与其做单个注意力，不如把q k v投影h次，做h个注意力，最后再投影回来，Linear的作用就是把向量投影到较低的维度 h = 8 用8个头，每次除以8，投影到64维 做多头的原因：因为注意力计算没有过程里没有可以学习的参数，让不同的Linear学习不同的特征，投影（线性层）的权重W是可以学的，可以学H个投影方法，来匹配不同的模式需要的一些相似函数，有点像有多个输出通道的感觉 Position-wise 前馈神经网络 x是query的输出，也就是512维，MLP把它投影到2048，又投影回去 左边transfomer，右边RNN，所以transformer用的是序列的全局信息 Positional Embeddingattention没有时序信息，因为输出是value加权和，权重是value和key之间的距离，和时序信息无关，词的顺序会变值不会变。RNN上一时刻输出到下一个时刻输入，本来就有位置信息。 用512向量表示位置数字，用周期不一样的sin和cos函数算出来的 为什么要自用注意力做实验和其他 循环层卷积层比较，比较好，复杂度低","categories":[{"name":"算法","slug":"算法","permalink":"https://heart74.github.io/categories/算法/"}],"tags":[{"name":"学习","slug":"学习","permalink":"https://heart74.github.io/tags/学习/"}],"keywords":[{"name":"算法","slug":"算法","permalink":"https://heart74.github.io/categories/算法/"}]},{"title":"cascade_rcnn","slug":"cascade-rcnn","date":"2023-04-19T03:10:13.000Z","updated":"2024-03-19T08:21:42.582Z","comments":true,"path":"2023/04/19/cascade-rcnn/","link":"","permalink":"https://heart74.github.io/2023/04/19/cascade-rcnn/","excerpt":"","text":"Two StageStage1用Region Proposal Network (RPN)生成高质量的预选区域(RP)，Stage2用检测头以这些RP为输入，进行最终框框坐标的输出以及类别的判断。 代表算法：R-CNN、Fast R-CNN、Faster R-CNN和R-FCN等 RCNN(Region with CNN features)先用搜索算法（selective search）选出一些rp，将这些rp划分的图片rescale到固定的大小，然后输入预训练好的CNN获得features。最后用SVM对这些features作目标存在判断和分类。 Faster RCNN提出了RPN(Region Proposal Network)，可以不费力地生成RP。 rp生成后，送入到Fast R-CNN结构中，计算每个proposal和标签框之间的iou，通过人为的设定一个IoU阈值（通常为0.5），把这些Proposals分为正样本（前景）和负样本（背景），并对这些正负样本采样，使得他们之间的比例尽量满足（1:3，二者总数量通常为128），之后这些proposals（128个）被送入到Roi Pooling，最后进行类别分类和box回归。 RPN head完整的图片输入CNN，得到完整的feature，根据这个总feature划分多个锚框(anchor box)。以一个feature像素点为中心，不同的长宽比和缩放比来生成该像素点的不同的锚框。每个像素点都有这一系列锚框。 得到锚框后，对每个框内的feature做一个前景和背景的二分类，用于判断目标是否位于锚框内。此外还需要将锚框调整到和bounding box相近的状态，可以用卷积完成这里两个个任务。一部分输出分类矩阵：rpn_cls_score，一部分输出调整后的边界框：rpn_bbox_pred。 接着RPN会根据这里两个值输出rpn_rois（Region of Interests）：表示可能有目标的框；和rpn_roi_probs：包含目标的可能性。这两者组成输出给rcnn的proposal，此时的回归和分类都比较粗糙，需要rcnn进一步精细化。 FPN(Feature Pyramid Networks)依赖CNN给出的最后一层feature能够很好地分类，但是对目标框的检测就没有那么友善。FPN提出对每一层的feature都去做分类和回归任务。因此每一层都有一个RPN头。 Cascade RCNN对于Faster RCNN，IoU的设置对结果影响很大。如果IoU设置较小，那么预测框将会包含大量背景噪声信息预测，精度降低；如果IoU设置较大，那么符合标准的预测框会大量减少，容易过拟合。只有当设置的预测框IoU和rp的IoU接近才有比较好的效果。 Cascade RCNN提出级联多个rcnn头，从H1到H3逐步增加IoU的阈值，每次都重新对RP进行采样，好逐步学到多层次的信息，适应不同的分布。","categories":[{"name":"技术","slug":"技术","permalink":"https://heart74.github.io/categories/技术/"}],"tags":[],"keywords":[{"name":"技术","slug":"技术","permalink":"https://heart74.github.io/categories/技术/"}]},{"title":"yolov8","slug":"yolov8","date":"2023-03-19T02:12:49.000Z","updated":"2024-03-19T08:08:50.524Z","comments":true,"path":"2023/03/19/yolov8/","link":"","permalink":"https://heart74.github.io/2023/03/19/yolov8/","excerpt":"","text":"v8网络结构 特性和改动 上图右下角是 BCE+CIOU+DFL 提供了一个全新的SOTA模型，包括P5640和P61280分辨率的目标检测网络和基于YOLACT的实例分割模型。和YOLOv5一样，基于缩放系数也提供了N/S/M/L/X尺度的不同大小模型，用于满足不同场景需求 将CSP结构换成了梯度流更丰富的C2f结构，并对不同模型调整了不同的通道数，对模型结构微调(由于C2f结构有着更多的残差连接，所以其有着更丰富的梯度流。) Head部分相比yolov5改动较大，换成了解耦头结构，将分类和检测头分离，同时也从Anchor-Based换成了Anchor Free Loss计算方面采用了TaskAlignedAssignedAssigner正样本分配策略，并引入了Distribution Focal Loss 训练的数据增强部分，引入了最后10个epoch关闭Mosiac增强的操作，可以有效地提升精度 骨干网络和Neck的具体变化 DFL介绍： 效果：良心技术，别问，问就是无cost涨点 一句话总结：基于任意one-stage 检测器上，调整框本身与框质量估计的表示，同时用泛化版本的GFocal Loss训练该改进的表示，无cost涨点（一般1个点出头）AP https://zhuanlan.zhihu.com/p/147691786 Loss计算","categories":[{"name":"技术","slug":"技术","permalink":"https://heart74.github.io/categories/技术/"}],"tags":[],"keywords":[{"name":"技术","slug":"技术","permalink":"https://heart74.github.io/categories/技术/"}]},{"title":"yolov5","slug":"yolov5","date":"2023-01-10T11:50:00.000Z","updated":"2024-03-19T07:06:49.745Z","comments":true,"path":"2023/01/10/yolov5/","link":"","permalink":"https://heart74.github.io/2023/01/10/yolov5/","excerpt":"","text":"框架图Focus模块已经被stem layer替换，作用都是下采样 相较于v3，把SPP换成了SPPF，由并行到串行，效率更高，计算结果一样 YOLOv4 和 YOLOv5 都使用 CSPDarknet作为BackBone，从输入图像中提取丰富的特征信息。CSPNet叫做Cross Stage Partial Network，跨阶段局部网络。其解决了其他大型卷积网络结构中的重复梯度问题，减少模型参数和FLOPS。这对YOLO 有重要的意义，即保证了推理速度和准确率，又减小了模型尺寸。 数据增强MosiaicCopy Paste仿射变换MixUpAlbumentations滤波、直方图均衡化、改变图片质量 HSVFLIP训练策略 损失 平衡不同尺度损失 消除Grid敏感度 匹配正样本 问题obj损失的CIOU和loc损失的CIOU什么区别关于损失可以看yolov3的介绍，obj损失是置信度损失，用IOUorCIOU计算，用BCE算的，而loc是回归损失（预测框的坐标），损失本身就是CIOU，回归损失只计算正样本的 Stem layer是什么 Stemblock 结构将输出的尺寸缩减为输入的 1/4，多用于轻量化网络，完成下采样操作，可以用于 YOLOv5 网络模型中原始的卷积下采样操作，减少参数量。 Stemblock 结构是 PeleeNet 中用于下采样的方法。该模块能够确保较强的特征表达能力且能够减少大量的参数 由上图可以看到原始 Stemblock 结构最终将输出的尺寸缩减为输入的 1/4，参照 Stemblock 结构并对其进行修改使其只完成一次下采样即可，主要目的是替代 YOLOv5 网络模型中原始的卷积下采样操作，减少参数量。因此最终使用的修改后的 stemblock 结构如下图所示 最终yolov5使用的是，缩减为输出的1/2","categories":[{"name":"技术","slug":"技术","permalink":"https://heart74.github.io/categories/技术/"}],"tags":[],"keywords":[{"name":"技术","slug":"技术","permalink":"https://heart74.github.io/categories/技术/"}]},{"title":"yolov4","slug":"yolov4","date":"2022-10-24T01:34:15.000Z","updated":"2024-03-19T02:18:27.979Z","comments":true,"path":"2022/10/24/yolov4/","link":"","permalink":"https://heart74.github.io/2022/10/24/yolov4/","excerpt":"","text":"v4 相较v3，引入了CSP层，可以增强CNN的学习能力，移除计算瓶颈，最后能减少内存消耗，Darknet同样是53 SPP PAN Backbone 消除Grid敏感程度当gt 在gird的边界上时，要求sigmiod（x）=0，但是当x负无穷才会趋近于0，不可取 优化后，取得的值域变成[-0.5，1.5] 优化Anchor","categories":[{"name":"技术","slug":"技术","permalink":"https://heart74.github.io/categories/技术/"}],"tags":[],"keywords":[{"name":"技术","slug":"技术","permalink":"https://heart74.github.io/categories/技术/"}]},{"title":"yolov1-v3","slug":"yolov1-v3","date":"2022-10-18T11:55:23.000Z","updated":"2024-03-19T07:04:10.275Z","comments":true,"path":"2022/10/18/yolov1-v3/","link":"","permalink":"https://heart74.github.io/2022/10/18/yolov1-v3/","excerpt":"","text":"v1 YOLOv1对小目标检测差，每个cell只测两个框，两个框都是一个类别的，当小目标聚集在一起，效果很差 定位不准确 yolov2 相较于v1的提升 BN每个卷积后面添加了BN层，减少了一系列正则化处理， 更高分辨率的分类器一开始yolov1用的224x224预训练，yolov2采用更大的分类尺寸448x448 使用基于Anchor的边界框预测简化了问题，更加容易学习和收敛，召回率增加 Anchor聚类使网络更容易学习 直接位置预测对预测的相对Anchor的坐标偏移量进行了限制 细粒度特征关注小目标，类似resnet的pass through方法，融合高层和低层体征 多尺度训练每10个batch，随机选择图片尺寸，{320,352,…..608}的尺寸 BackBoneDarknet-19 19个卷积层 yolov3backbone 没有通过最大池化，用卷积层步数为2进行下采样，卷积核个数少，参数少，速度快 在小特征图（1）预测大目标，大特征图（3）预测小目标 目标边界框的预测（和v2相同） 正负样本匹配 对每个GT，分配一个Anchor作为正样本 损失 CIOU IOU loss GIOU 缺点：某些情况下会退化成IOU，但是问题不大？ DIOU LOSS CIou Loss Focal Loss 增加难分样本权重，减少易分样本权重，容易受到噪声干扰 Mosaic SPP 问题anchor到底是什么？先验候选框？往anchor上去学习，降低学习难度，加快训练速度 正负样本？预测正确的框和预测失败的框 正样本： 对象中心落在网格内：对于每个真实对象（ground truth object），其边界框（bounding box）的中心落在哪个网格单元内，那个网格单元就负责预测这个对象。因此，该网格单元和与之对应的预测边界框成为“正样本” 存在性置信度：与该网格相关联的“对象存在的置信度”应该接近1 类别标签：该网格单元还需要预测该对象的类别 负样本： 对象中心不落在网格内：如果一个网格单元内没有任何真实对象（ground truth object）的中心，那么该网格单元就是一个“负样本” 存在性置信度：与这些负样本网格相关联的“对象存在的置信度”接近0 用了BN为啥偏置没用","categories":[{"name":"技术","slug":"技术","permalink":"https://heart74.github.io/categories/技术/"}],"tags":[],"keywords":[{"name":"技术","slug":"技术","permalink":"https://heart74.github.io/categories/技术/"}]},{"title":"blog书写说明","slug":"blog书写说明","date":"2022-05-10T07:58:39.000Z","updated":"2024-03-09T08:37:46.058Z","comments":true,"path":"2022/05/10/blog书写说明/","link":"","permalink":"https://heart74.github.io/2022/05/10/blog书写说明/","excerpt":"","text":"主题使用说明https://docs.hojun.cn/sakura/docs/#/home?id=%E4%BA%A4%E6%B5%81%E7%BE%A4 注释说明title: blog书写说明 // 博客标题 author: heart74 // 作者 avatar: &#39;https://cdn.jsdelivr.net/gh/heart74/cdn@1.2/img/custom/avatar.jpg&#39; // 头像 authorLink: &#39;https://heart74.github.io&#39; // 博客链接 authorAbout: I trust nobody and nobody trusts me authorDesc: I trust nobody and nobody trusts me categories: 技术 // 代表index.html菜单栏的归档，新增categories的条目在config.yaml的归档里未创建时就不会再index.html显示 comments: true // 是否可以评论 photos: &#39;https://cdn.jsdelivr.net/gh/heart74/cdn@1.2/img/wlop/8.jpg&#39; // 文章背景 date: 2022-05-10 15:58:39 tags: // 代表index.html菜单栏的清单，新增tag的条目在config.yaml的清单里未创建时就不会再index.html显示 keywords: // 好像没啥用 description: 博客书写时顶部config说明 //文章描述 菜单栏各项图标修改源图标：https://fontawesome.com/icons 下面截图链接： http://www.tsdqq.net/web/font_awesome_4.html","categories":[{"name":"技术","slug":"技术","permalink":"https://heart74.github.io/categories/技术/"}],"tags":[],"keywords":[{"name":"技术","slug":"技术","permalink":"https://heart74.github.io/categories/技术/"}]},{"title":"npm和hexo安装及使用","slug":"npm-hexo-install","date":"2022-03-09T07:35:14.000Z","updated":"2024-03-09T07:58:44.624Z","comments":true,"path":"2022/03/09/npm-hexo-install/","link":"","permalink":"https://heart74.github.io/2022/03/09/npm-hexo-install/","excerpt":"","text":"当前博客npm和hexo版本 npm安装：在官网找上图指定版本安装即可 hexo 安装npm查看hexo cli版本命令: npm view hexo-cli versions 安装指定版本hexo-cli: npm install -g hexo-cli@4.2.0 hexo常用命令hexo new blog_nname # 创建博客.md hexo g # 渲染并生成页面 hexo s # 本地服务预览 hexo d # 部署 hexo clean #清除缓存，若是网页正常情况下可以忽略这条命令 配置有两个配置文件 一个主题的config.yml一个站点的config.yml，和github关联操作： 关联域名通过github的ip和自己的域名绑定即可 更换主题在blog目录中的themes文件夹中查看你自己主题是什么，下载主题文件并在站点的配置文件config.yaml修改名称即可 图床目前使用github，也可以使用其他图床，工具是typora + PicGo","categories":[{"name":"技术","slug":"技术","permalink":"https://heart74.github.io/categories/技术/"}],"tags":[],"keywords":[{"name":"技术","slug":"技术","permalink":"https://heart74.github.io/categories/技术/"}]},{"title":"Information Visualation","slug":"InformationVisualization","date":"2021-01-09T04:08:05.000Z","updated":"2021-01-10T05:49:51.000Z","comments":true,"path":"2021/01/09/InformationVisualization/","link":"","permalink":"https://heart74.github.io/2021/01/09/InformationVisualization/","excerpt":"","text":"Information Visualization Tips: The title of the picture is a hyperlink. Click to jump to the web page of the visual chart. EchartsInformation Visualization-Echarts(English) Information Visualization-Echarts(Chinese) TableauInformation Visualization-Tableau MatplotlibInformation Visualization-Matplotlib","categories":[{"name":"技术","slug":"技术","permalink":"https://heart74.github.io/categories/技术/"}],"tags":[],"keywords":[{"name":"技术","slug":"技术","permalink":"https://heart74.github.io/categories/技术/"}]},{"title":"hadoop_problems_solve","slug":"hadoop","date":"2020-06-02T09:41:53.000Z","updated":"2020-06-02T09:44:13.000Z","comments":true,"path":"2020/06/02/hadoop/","link":"","permalink":"https://heart74.github.io/2020/06/02/hadoop/","excerpt":"","text":"hadoop常见疑问及解答1、4个配置文件(含注释：单机完全分布都可用)完全分布式部署建议在master上先配置好网络，搭建好单机hadoop后复制整个master虚拟机为slave1，2…n 不过不太清楚单机和伪分布式的区别呢 core-site.xml &lt;configuration&gt; &lt;!-- 这个属性用来指定namenode的hdfs协议的文件系统通信地址，可以指定一个主机+端口，也可以指定为一个namenode服务（这个服务内部可以有多台namenode实现hadoop的namenode服务 --&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://master:9000&lt;/value&gt; &lt;!--master为自己的主机名后面的master同--&gt; &lt;/property&gt; &lt;!-- 指定hadoop运行时产生文件的存储路径 tmp 提前创建好，前面用file:表示是本地目录。hadoop在运行过程中肯定会有临时文件或缓冲之类的，必然需要一个临时目录来存放，这里就是指定这个的 --&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/******/hadoop/tmp&lt;/value&gt; &lt;!--/******/为根目录到自己的hadoop安装目录--&gt; &lt;/property&gt; &lt;/configuration&gt; hdfs-site.xml &lt;property&gt; &lt;!--设置hdfs副本数量：默认为3--&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;2&lt;/value&gt; &lt;/property&gt; &lt;!-- namenode数据的存放地点。也就是namenode元数据存放的地方，记录了hdfs系统中文件的元数据--&gt; &lt;property&gt; &lt;name&gt;dfs.name.dir&lt;/name&gt; &lt;value&gt;/*******/hadoop/hdfs/name&lt;/value&gt; &lt;!--/******/为根目录到自己的hadoop安装目录--&gt; &lt;/property&gt; &lt;property&gt; &lt;!-- datanode数据的存放地点。也就是block块存放的目录了--&gt; &lt;name&gt;dfs.data.dir&lt;/name&gt; &lt;value&gt;/******/hadoop/hdfs/data&lt;/value&gt; &lt;!--/******/为根目录到自己的hadoop安装目录--&gt; &lt;/property&gt; mapred-site.xml &lt;!-- 通知框架MR使用YARN --&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt; &lt;!---- 指定mr框架jobhistory的内部通讯地址 --&gt; &lt;property&gt; &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt; &lt;value&gt;master:10020&lt;/value&gt; &lt;/property&gt; &lt;!---- 指定mr框架web查看的地址 --&gt; &lt;property&gt; &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt; &lt;value&gt;master:19888&lt;/value&gt; &lt;/property&gt; yarn-site.xml &lt;!--这个文件就是配置资源管理系统yarn了，其中主要指定了一些节点资源管理器nodemanager，以及总资源管理器resourcemanager的配置。可以看到这个配置中，跟mapreduce框架是相关的。可见yarn首先是为了支持mapreduce这个模型，之后很多其他的框架都是基于mapreduce以及yarn的功能基础上开发出来的。--&gt; &lt;!--- 启用的资源调度器主类 --&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services.mapreduce.shuffle.class&lt;/name&gt; &lt;value&gt;org.apache.mapred.ShuffleHandler&lt;/value&gt; &lt;/property&gt; &lt;!--- ResourceManager 对客户端暴露的地址。客户端通过该地址向RM提交应用程序，杀死应用程序等 --&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.address&lt;/name&gt; &lt;value&gt;master:8032&lt;/value&gt; &lt;/property&gt; &lt;!-- ResourceManager 对ApplicationMaster暴露的访问地址。ApplicationMaster通过该地址向RM申请资源、释放资源等 --&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.scheduler.address&lt;/name&gt; &lt;value&gt;master:8030&lt;/value&gt; &lt;/property&gt; &lt;!-- ResourceManager 对NodeManager暴露的地址.。NodeManager通过该地址向RM汇报心跳，领取任务等 --&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.resource-tracker.address&lt;/name&gt; &lt;value&gt;master:8031&lt;/value&gt; &lt;/property&gt; &lt;!-- 对管理员暴露的访问地址。管理员通过该地址向RM发送管理命令等 --&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.admin.address&lt;/name&gt; &lt;value&gt;master:8033&lt;/value&gt; &lt;/property&gt; &lt;!-- ResourceManager对外web ui地址。用户可通过该地址在浏览器中查看集群各类信息 --&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.webapp.address&lt;/name&gt; &lt;value&gt;master:8088&lt;/value&gt; &lt;/property&gt; &lt;!-- NodeManager上运行的附属服务。需配置成mapreduce_shuffle，才可运行MapReduce程序 --&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt; 2、hdfs常用操作# 查看帮助： hadoop fs -help &lt;cmd&gt; # 上传： hadoop fs -put &lt;linux上文件&gt; &lt;hdfs上的路径&gt; # 查看文件内容： hadoop fs -cat &lt;hdfs上的路径&gt; # 查看文件列表： hadoop fs -ls / # 下载文件： hadoop fs -get &lt;hdfs上的路径&gt; &lt;linux上文件&gt; 3、stop-yarn.sh 时NodeManager stop 异常报错如下： slave1: nodemanager did not stop gracefully after 5 seconds: killing with kill -9 查阅好多资料结论：官网未解决 4、jps命令后slave1,slave2上不出现datanode进程，stop-all.sh时也无datanode去stop（单机和伪分布式则是master里没有datanode进程）解决： 原因可能是 hdfs/data/current/VERSION 和 hdfs/name/current/VERSION 的clusterid 不同 故： 1、修改虚拟机master上：hadoop/hdfs/data/current/VERSION 文件里的clusterid 与 hadoop/hdfs/name/current/VERSION clusterid 相同 2、修改所有的slave上：hadoop/hdfs/data/current/VERSION 文件里的clusterid与master上 hadoop/hdfs/name/current/VERSION clusterid 相同 如果是单机和伪分布式hadoop只需执行第一步 5、stop-all.sh后浏览器localhost:50070的datanode界面只随机显示一个slave和datanode解决: 因为slave们是从master完全复制过来的，故hadoop/hdfs/data/current/VERSION 文件里的datanodeuuid和storageID，都相同,slave之间会产生冲突(来自网络),故： 如果有两个slave则只需修改一个slave中hadoop/hdfs/data/current/VERSION 文件里的datanodeuuid和storageID，两者都是字母数字的组合，随便修改几个数字字母为别的值就可 6、这些都是我自己遇到并解决的问题，后续应该还会持续更新敬请期待！博客首页有联系方式欢迎提问（评论功能暂未开通）","categories":[{"name":"技术","slug":"技术","permalink":"https://heart74.github.io/categories/技术/"}],"tags":[],"keywords":[{"name":"技术","slug":"技术","permalink":"https://heart74.github.io/categories/技术/"}]},{"title":"MarkDown语法","slug":"MarkDown语法","date":"2020-02-22T09:07:33.000Z","updated":"2020-02-22T09:15:08.000Z","comments":true,"path":"2020/02/22/MarkDown语法/","link":"","permalink":"https://heart74.github.io/2020/02/22/MarkDown语法/","excerpt":"","text":"Markdown教学1、代码块#代码块语法 ```java ```python ```shell 1.python代码 def hello: print(&#39;hello world&#39;) hello() 2.java代码 public class Test{ public void main() } 3.shell # java -jar blog start 方便起见下面的新语法我都放到代码块里了☟2、标题六个等级 # 一级标题 ## 二级标题 ### 注意&#39;#&#39;号和内容之间加空格 ###### 一直到六级标题 一级标题二级标题注意’#’号和内容之间加空格一直到六级标题3、字体# 加粗 **我要加粗** # 代码高亮显示 ==心脏== # 删除线 ~~被删除的文字~~ # 斜体 *斜体* 我要加粗 ==心脏== 被删除的文字 斜体 4、引用# 引用语法 &gt;作者：heart &gt;&gt;作者：heart &gt;&gt;&gt;作者：heart 作者：heart 作者：heart 作者：heart 5、分割线#分割线 --- 6、图片插入# 在线图片 / 本地图片 ![my_picture](5bcae8399fdb4.jpg) --图片路径 7、超链接# 超链接语法 [hello_baidu](https://www.baidu.com/) hello_baidu 8、列表# 无序列表 - 目录一 - 目录二 - 目录三 #&#39;数字&#39;+&#39;.&#39;+&#39; &#39;+内容 1. 首页 2. hello 目录一 目录二 目录三 首页 hello 9、表格# 右键点击插入表格 成绩 语文 数学 33 33","categories":[{"name":"技术","slug":"技术","permalink":"https://heart74.github.io/categories/技术/"}],"tags":[{"name":"悦读","slug":"悦读","permalink":"https://heart74.github.io/tags/悦读/"}],"keywords":[{"name":"技术","slug":"技术","permalink":"https://heart74.github.io/categories/技术/"}]},{"title":"小记","slug":"小记","date":"2020-02-08T05:14:00.000Z","updated":"2021-10-23T02:07:17.000Z","comments":true,"path":"2020/02/08/小记/","link":"","permalink":"https://heart74.github.io/2020/02/08/小记/","excerpt":"","text":"hi guy！为什么会有这个呢？ 偶然看见一个非常漂亮的博客，特别羡慕。于是就想自己整一个。然而假期全交给了==王者荣耀==，我太难了巧了。最近由于一只蝙蝠，上不了学，他喵的网上看ppt那些又看不进去，老想玩手机。 于是不如搞个这个玩玩，如你所见，我成功了哈哈哈哈。功夫不负有心人，找了个个人觉得很好看的主题。 用github pages，整出了这个博客。至于买自己的域名，慢慢来，不急，来日方长。 毕竟是第一次尝试，自我感觉还挺良好。 就是好多分类标签啥的还没写自己的东西，是空白的，但是还是请多多关注，该有的都会有的，从零开始，我会在这里和大家分享自己在学习，生活各个方面的快乐。一起进步！","categories":[{"name":"生活","slug":"生活","permalink":"https://heart74.github.io/categories/生活/"}],"tags":[{"name":"悦读","slug":"悦读","permalink":"https://heart74.github.io/tags/悦读/"}],"keywords":[{"name":"生活","slug":"生活","permalink":"https://heart74.github.io/categories/生活/"}]}]}